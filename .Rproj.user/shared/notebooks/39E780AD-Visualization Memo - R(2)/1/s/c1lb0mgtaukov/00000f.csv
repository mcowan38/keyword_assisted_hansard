"0","# Source the custom stopwords script"
"0","source(""./stop words/custom_stopwords.R"")"
"0",""
"0","# Tokenize and clean, using imported stopword list"
"0","tokens_clean <- tokens("
"0","  key_corpus,"
"0","  remove_punct = TRUE,"
"0","  remove_numbers = TRUE,"
"0","  remove_symbols = TRUE,"
"0","  remove_separators = TRUE,"
"0","  remove_url = TRUE"
"0",") %>%"
"0","  tokens_tolower() %>%"
"0","  tokens_remove(pattern = custom_stops) %>%"
"0","  tokens_select(min_nchar = 3)"
"0",""
"0","# Convert to a Document-Feature Matrix and trim low-frequency terms"
"0","dfm_clean <- dfm(tokens_clean) %>%"
"0","  dfm_trim(min_termfreq = 3, min_docfreq = 3) # Adjust thresholds as needed"
"0",""
"0","# Remove empty docs"
"0","dfm_clean <- dfm_subset(dfm_clean, ntoken(dfm_clean) > 0)"
"0",""
"0","# Check the top features for stopwords"
"0","# topfeatures(dfm_clean, 20)"
